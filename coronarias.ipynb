{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":87814,"databundleVersionId":10024333,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-23T05:12:51.239678Z","iopub.execute_input":"2024-12-23T05:12:51.240115Z","iopub.status.idle":"2024-12-23T05:12:51.696239Z","shell.execute_reply.started":"2024-12-23T05:12:51.240079Z","shell.execute_reply":"2024-12-23T05:12:51.694841Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Importaciónde bibliotecas usadas\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom imblearn.over_sampling import SMOTE\nfrom collections import Counter\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.metrics import f1_score, precision_recall_curve\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T05:12:51.698319Z","iopub.execute_input":"2024-12-23T05:12:51.698946Z","iopub.status.idle":"2024-12-23T05:12:53.426895Z","shell.execute_reply.started":"2024-12-23T05:12:51.698911Z","shell.execute_reply":"2024-12-23T05:12:53.425923Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cargamos los datasets\ntrain = pd.read_csv('/kaggle/input/prediccion-de-sufrir-enfermedades-coronarias/train.csv')\ntest_public = pd.read_csv('/kaggle/input/prediccion-de-sufrir-enfermedades-coronarias/test_public.csv')\ntest_private = pd.read_csv('/kaggle/input/prediccion-de-sufrir-enfermedades-coronarias/test_private.csv')\n\n\nprint(\"Primeras filas de train (5 filas):\")\nprint(train.head())\n\nprint(\"\\nTipos de datos de train:\")\nprint(train.info())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T05:12:53.428575Z","iopub.execute_input":"2024-12-23T05:12:53.429052Z","iopub.status.idle":"2024-12-23T05:12:55.794034Z","shell.execute_reply.started":"2024-12-23T05:12:53.429024Z","shell.execute_reply":"2024-12-23T05:12:55.792748Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pre-procesamietno\n\n# Valores faltantes de cada conjunto de datos\nprint(\"\\nValores nulos de train:\")\nprint(train.isnull().sum())\nprint(\"\\nValores nulos de test_public:\")\nprint(test_public.isnull().sum())\nprint(\"\\nValores nulos de test_private:\")\nprint(test_private.isnull().sum())\n\n\n# Función para pre-procesamiento\ndef preprocesamiento(df, eliminar_id=True):\n    if eliminar_id:\n        col_irrelevante = [\"ID\"]\n        df = df.drop(columns=col_irrelevante, errors=\"ignore\")\n    for col in df.columns:\n        if df[col].dtype == \"object\":\n            df[col] = df[col].fillna(df[col].mode()[0])\n        else:\n            df[col] = df[col].fillna(df[col].median())\n    return df\n\n\n# Pre-preocesamiento para cada conjunto de datos\ntrain = preprocesamiento(train)\ntest_public = preprocesamiento(test_public, eliminar_id=False)\ntest_private = preprocesamiento(test_private, eliminar_id=False)\n\n# Valores nulos después del pre-procesamiento\nprint(\"\\nValores nulos en train.csv después del preprocesamiento:\")\nprint(train.isnull().sum())\nprint(\"\\nValores nulos en test_public.csv después del preprocesamiento:\")\nprint(test_public.isnull().sum())\nprint(\"\\nValores nulos en test_private.csv después del preprocesamiento:\")\nprint(test_private.isnull().sum())\n\n# Verificar las primeras filas de cada conjunto de datos\nprint(\"Primeras filas de train (5 filas) despues de pre-procesamiento:\")\nprint(train.head())\n\nprint(\"Primeras filas de test_public (5 filas) despues de pre-procesamiento:\")\nprint(test_public.head())\n\nprint(\"Primeras filas de test_private (5 filas) despues de pre-procesamiento:\")\nprint(test_private.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T05:12:55.795389Z","iopub.execute_input":"2024-12-23T05:12:55.795776Z","iopub.status.idle":"2024-12-23T05:12:56.378590Z","shell.execute_reply.started":"2024-12-23T05:12:55.795733Z","shell.execute_reply":"2024-12-23T05:12:56.377706Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Distribucion de datos (analisis para balanceo de clases)\n\n#Distribución de la variable objetivo (CHD_OR_MI)\nplt.figure(figsize=(8, 6))\nsns.countplot(x='CHD_OR_MI', data=train)\nplt.title('Distribución de CHD_OR_MI')\nplt.xlabel('Diagnóstico de enfermedad coronaria o infarto (0 = No, 1 = Sí)')\nplt.ylabel('Número de casos')\nplt.show()\n\n# Clases de la variable objetivo (CHD_OR_MI)'\nprint(\"\\nClases de la variable objetivo\")\nprint(train['CHD_OR_MI'].value_counts())\n\n# Matriz de correlación de las características numéricas\ncol_num = train.select_dtypes(include=['float64', 'int64']).columns\nmatriz_corre = train[col_num].corr()\n\n# Mapa de calor de la matriz de correlación\nprint(\"\\nMapa de calor de la matriz de correlación\")\nplt.figure(figsize=(12, 8))\nsns.heatmap(matriz_corre, annot=True, fmt='.2f', linewidths=0.5)\nplt.title('Matriz de Correlación')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T05:12:56.379674Z","iopub.execute_input":"2024-12-23T05:12:56.379945Z","iopub.status.idle":"2024-12-23T05:12:59.466973Z","shell.execute_reply.started":"2024-12-23T05:12:56.379922Z","shell.execute_reply":"2024-12-23T05:12:59.465751Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Balanceo de clases usando SMOTE\n\n# Definir la variable objetivo (CHD_OR_MI)\nX = train.drop(columns=['CHD_OR_MI'])\ny = train['CHD_OR_MI']\n\n# Distribución original de las clases de CHD_OR_MI\nprint(f'Distribución de clases de CHD_OR_MI: {Counter(y)}')\n\n# Usamos SMOTE para balancear las clases\nsmote = SMOTE(random_state=42)\nX_res, y_res = smote.fit_resample(X, y)\n\n# Mostrar la nueva distribución de clases después de SMOTE\nprint(f'Distribución de clases después de SMOTE: {Counter(y_res)}')\n\n# Crear un nuevo DataFrame con las características balanceadas\ntrain_res = pd.DataFrame(X_res, columns=X.columns)\ntrain_res['CHD_OR_MI'] = y_res\n\n# Figura de nueva distribución de clases de CHD_OR_MI\nplt.figure(figsize=(8, 6))\nsns.countplot(x='CHD_OR_MI', data=train_res)\nplt.title('Distribución de CHD_OR_MI después de SMOTE')\nplt.xlabel('Enfermedad coronaria o infarto (0 = No, 1 = Sí)')\nplt.ylabel('Nuemro de casos')\nplt.show()\n\n# Verificar las primeras filas de cada conjunto de datos para asegurarse de que el preprocesamiento se haya realizado correctamente\nprint(\"\\nPrimeras filas de train:\")\nprint(train.head())\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T05:12:59.468169Z","iopub.execute_input":"2024-12-23T05:12:59.468456Z","iopub.status.idle":"2024-12-23T05:13:02.517811Z","shell.execute_reply.started":"2024-12-23T05:12:59.468432Z","shell.execute_reply":"2024-12-23T05:13:02.516704Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Seleccion de caracteristicas\n\n# Definimos variable objetivo (CHD_OR_MI)\nX = train_res.drop(columns=['CHD_OR_MI'])\ny = train_res['CHD_OR_MI']\n\n# Dividir los datos en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Modelo de RandomForest para obtener la importancia de las características\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_train, y_train)\n\n# importancia de características\nimportancia = model.feature_importances_\n\n# DataFrame para características e importancias\nimportancia_carac = pd.DataFrame({\n    'caracteristica': X.columns,\n    'importancia': importancia\n})\n\n# Ver características importantes descendentemente\nimportancia_carac = importancia_carac.sort_values(by='importancia', ascending=False)\nplt.figure(figsize=(10, 6))\nsns.barplot(x='importancia', y='caracteristica', data=importancia_carac)\nplt.title('Importancia de características')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T05:13:02.518816Z","iopub.execute_input":"2024-12-23T05:13:02.519097Z","iopub.status.idle":"2024-12-23T05:14:56.767341Z","shell.execute_reply.started":"2024-12-23T05:13:02.519073Z","shell.execute_reply":"2024-12-23T05:14:56.766273Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Entrenamiento de modelo (RandomForest) con caracteristicas seleccioandas\n\n# Seleccionar las características más importantes usando un umbral\nsfm = SelectFromModel(model, threshold=0.01)\nsfm.fit(X_train, y_train)\n\n# Obtener las características seleccionadas\ncaracteristicas_select = X.columns[sfm.get_support()]\nprint(f'Características seleccionadas: {caracteristicas_select}')\n\n# Filtramios DataFrame con solo las características seleccionadas\nX_train_select = X_train[caracteristicas_select]\nX_test_select = X_test[caracteristicas_select]\n\n# Verificar las primeras filas de las características seleccionadas en el conjunto de entrenamiento\nprint(X_train_select.head())\n\n# Entrenar nuevamente el modelo con las características seleccionadas\nmodel.fit(X_train_select, y_train)\n\n# Realizar predicciones con el conjunto de prueba\ny_pred = model.predict(X_test_select)\n\n# Convertir la matriz de confusión en un DataFrame para mejor visualización\ncm = confusion_matrix(y_test, y_pred)\ncm_df = pd.DataFrame(cm, index=['Clase Negativa', 'Clase Positiva'], columns=['Predicción Negativa', 'Predicción Positiva'])\n\n# mMtriz de confusión en texti\nprint(\"\\nMatriz de confusión:\")\nprint(cm_df)\n\n# Mapa de calor de la matriz de confusión\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm_df, annot=True)\nplt.title('Matriz de Confusión', fontsize=16)\nplt.ylabel('Clase Real', fontsize=12)\nplt.xlabel('Clase Predicha', fontsize=12)\nplt.show()\n\n# Calcular el F1 Score\nf1 = f1_score(y_test, y_pred)\nprint(f'F1 Score: {f1}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T05:14:56.768429Z","iopub.execute_input":"2024-12-23T05:14:56.768746Z","iopub.status.idle":"2024-12-23T05:18:35.581389Z","shell.execute_reply.started":"2024-12-23T05:14:56.768719Z","shell.execute_reply":"2024-12-23T05:18:35.580279Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluamos el modelo con test_public\nX_test_public = test_public[caracteristicas_select]\ny_test_public = test_public['CHD_OR_MI']\ny_test_public_pred = model.predict(X_test_public)\n\n# F1 Score en test_public\nf1_test_public = f1_score(y_test_public, y_test_public_pred)\nprint(f'F1-Score para test_public: {f1_test_public}')\n\n# Predicción en test_private\nX_test_private = test_private[caracteristicas_select]\ny_test_private_pred = model.predict(X_test_private)\n\n# Creamos resultados (test_public y test_private)\npredicciones_public = pd.DataFrame({\n    'ID': test_public['ID'],\n    'CHD_OR_MI': y_test_public_pred\n})\n\npredicciones_private = pd.DataFrame({\n    'ID': test_private['ID'],\n    'CHD_OR_MI': y_test_private_pred\n})\n\n# Juntamos las predicciones de test_public y test_private\nresults = pd.concat([predicciones_public, predicciones_private], axis=0)\n\n# Guardar las predicciones en un archivo (csv)\nresults.to_csv('resultados.csv', index=False)\nresults.to_csv('submission.csv', index=False)\n\nprint(\"Se creo archivo de resultados :D\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T05:18:35.583948Z","iopub.execute_input":"2024-12-23T05:18:35.584251Z","iopub.status.idle":"2024-12-23T05:18:39.278210Z","shell.execute_reply.started":"2024-12-23T05:18:35.584224Z","shell.execute_reply":"2024-12-23T05:18:39.277179Z"}},"outputs":[],"execution_count":null}]}